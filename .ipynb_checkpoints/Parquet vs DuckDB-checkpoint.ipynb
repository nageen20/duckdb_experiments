{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00da1307-41da-4998-a33c-1ac861dad770",
   "metadata": {},
   "source": [
    "## Parquet and DuckDB - Analyzing Large Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64742580-8d83-4824-9e66-4c156bd875f1",
   "metadata": {},
   "source": [
    "In this jupyter notebook we explore the capabilities of DuckDB and Parquet file. We used the bitcoin dataset from Kaggle that has about 220 million rows. We first compute some technical indicators using Parquet files and DuckDB. Then we compare this with technical indicators computation using native DuckDB table format. You can find the accompanying blog here - https://learn2infiniti.com/parquet-and-duckdb-analyzing-large-datasets/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5eb61b6-810e-455c-a228-91dfa23cec36",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1742ecb8-bba6-4657-a4d1-6053291fed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74781554-b74d-4987-9757-7bce32fbe80d",
   "metadata": {},
   "source": [
    "### Loading parquet files of the bit coin datasets\n",
    "The dataset is available as two large csv files containing a total of 220 million rows. The csv files are converted to parquet files outside this jupyter notebook. In this notebook, we first read both the paruqet files using DuckDB python APIs. DuckDB provides a way to read multiple parquet files at the same time by providing a list of files.\n",
    "\n",
    "1. Note that parquet files path is provided as list.\n",
    "2. We see the load times are in milli seconds because DuckDB doesn't yet read the parquet files into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cac7c53-d5fb-49c3-ba5a-617aa4e11117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.2 ms\n",
      "Wall time: 66.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load both the parquet files\n",
    "bc_full_dataset = duckdb.sql('''SELECT * \n",
    "                                FROM read_parquet(['data/bc_dataset_snappy_1.parquet','data/bc_dataset_snappy_2.parquet'])''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12c1aed-0ce0-454b-b2ce-fd14f536869c",
   "metadata": {},
   "source": [
    "### Writing the two separate datasets as a single parquet file.\n",
    "In this step we write the combined datasets variable into a new parquet file. We do this to avoid any inefficincies that can occur because of multiple files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8194feba-4cb4-4327-bf61-e7f95cfb5ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 21s\n",
      "Wall time: 4min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x2d83e42f830>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# We are writing the above combined variable to a parquet file. By default DuckDB uses Snappy compression. \n",
    "duckdb.execute('''COPY\n",
    "    (SELECT *, YEAR(\"Open Time\") as year, MONTH(\"Open Time\") as month FROM bc_full_dataset)\n",
    "    TO 'data/bc_full_dataset_snappy.parquet'\n",
    "    (FORMAT 'parquet', CODEC 'snappy');''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "42841587-c354-4ccf-9816-8d379549081e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 46.9 ms\n",
      "Wall time: 99.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bc_full_dataset = duckdb.sql('''SELECT * \n",
    "                                FROM read_parquet('data/bc_full_dataset_snappy.parquet')''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f730964a-f7ac-4d60-a67d-c435e2e7591c",
   "metadata": {},
   "source": [
    "### Calculating technical indicators\n",
    "We start with calculating simple technical indicators. We calculate the moving average 50 seconds and moving average 200 seconds. This is to compare with the moving average computed on the single dataset in the previous notebook. Notice that it took 3min 47sec to process the moving averages on a 220 million rows dataset. In the previous notebook, it took under a minute to calculate the same on a 110 million row dataset. This shows that performance seems to degrade slightly with increased data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de325bcf-f003-4d74-b313-0caac893fe4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────────────────┬─────────┬───────────────────┬───────────────────┐\n",
      "│      Open Time      │  Close  │       ma50        │       ma200       │\n",
      "│      timestamp      │ double  │      double       │      double       │\n",
      "├─────────────────────┼─────────┼───────────────────┼───────────────────┤\n",
      "│ 2017-08-17 04:00:28 │ 4261.48 │           4261.48 │           4261.48 │\n",
      "│ 2017-08-17 04:00:29 │ 4261.48 │           4261.48 │           4261.48 │\n",
      "│ 2017-08-17 04:00:30 │ 4261.48 │           4261.48 │           4261.48 │\n",
      "│ 2017-08-17 04:00:31 │ 4261.48 │           4261.48 │           4261.48 │\n",
      "│ 2017-08-17 04:00:32 │ 4261.48 │           4261.48 │           4261.48 │\n",
      "│ 2017-08-17 04:00:33 │ 4261.48 │           4261.48 │           4261.48 │\n",
      "│ 2017-08-17 04:00:34 │ 4261.48 │           4261.48 │           4261.48 │\n",
      "│ 2017-08-17 04:00:35 │ 4261.48 │           4261.48 │           4261.48 │\n",
      "│ 2017-08-17 04:00:36 │ 4261.48 │           4261.48 │           4261.48 │\n",
      "│ 2017-08-17 04:00:37 │ 4261.48 │ 4261.479999999999 │ 4261.479999999999 │\n",
      "│          ·          │    ·    │         ·         │         ·         │\n",
      "│          ·          │    ·    │         ·         │         ·         │\n",
      "│          ·          │    ·    │         ·         │         ·         │\n",
      "│ 2017-08-17 06:46:58 │ 4345.45 │ 4345.450000000001 │ 4345.449999999996 │\n",
      "│ 2017-08-17 06:46:59 │ 4345.45 │ 4345.450000000001 │ 4345.449999999996 │\n",
      "│ 2017-08-17 06:47:00 │ 4345.45 │ 4345.450000000002 │ 4345.449999999995 │\n",
      "│ 2017-08-17 06:47:01 │ 4345.45 │ 4345.450000000002 │ 4345.449999999995 │\n",
      "│ 2017-08-17 06:47:02 │ 4345.45 │ 4345.450000000002 │ 4345.449999999995 │\n",
      "│ 2017-08-17 06:47:03 │ 4345.45 │ 4345.450000000002 │ 4345.449999999995 │\n",
      "│ 2017-08-17 06:47:04 │ 4345.45 │ 4345.450000000003 │ 4345.449999999995 │\n",
      "│ 2017-08-17 06:47:05 │ 4345.45 │ 4345.450000000003 │ 4345.449999999994 │\n",
      "│ 2017-08-17 06:47:06 │ 4345.45 │ 4345.450000000003 │ 4345.449999999994 │\n",
      "│ 2017-08-17 06:47:07 │ 4345.45 │ 4345.449999999999 │ 4345.449999999998 │\n",
      "├─────────────────────┴─────────┴───────────────────┴───────────────────┤\n",
      "│ ? rows (>9999 rows, 20 shown)                               4 columns │\n",
      "└───────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "Total time taken: 227.11045241355896\n",
      "CPU times: total: 14min 15s\n",
      "Wall time: 3min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Calculate the 50 seconds moving average and 200 seconds moving average and show the output.\n",
    "start_time = time.time()\n",
    "duckdb.sql('''\n",
    "                SELECT \"Open Time\",\n",
    "                        Close,\n",
    "                        AVG(\"Close\") OVER ( ORDER BY \"Open Time\"  \n",
    "                                            RANGE BETWEEN INTERVAL 50 SECONDS PRECEDING\n",
    "                                              AND INTERVAL 0 SECONDS FOLLOWING) as ma50,\n",
    "                        AVG(\"Close\") OVER ( ORDER BY \"Open Time\" \n",
    "                                            RANGE BETWEEN INTERVAL 200 SECONDS PRECEDING\n",
    "                                              AND INTERVAL 0 SECONDS FOLLOWING) as ma200\n",
    "                FROM bc_full_dataset\n",
    "''').show()\n",
    "end_time = time.time()\n",
    "print(f'Total time taken: {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb39abd2-d9db-48cf-8cdc-a469ec3df8bf",
   "metadata": {},
   "source": [
    "### Adding more technical indicators\n",
    "In the next step, we add more technical indicators to our arsenal. In this step we calculate the following technical indicators.\n",
    "1. Moving average 14 seconds\n",
    "2. Moving average 28 seconds\n",
    "3. Standard deviation 14 seconds. This is used in calculating the bollinger bands\n",
    "4. Average gain and loss in last 14 seconds. This is used in calculating RSI.\n",
    "\n",
    "```Note - Note that I am no expert at technical analysis and I have taken the definitions from internet and tried to implement here. This may not be the most efficient and accurate implementation of the indicators.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2dcfd8a5-47ad-4956-84e1-4acf03e39573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken: 0.0752406120300293\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 75.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Calculate the window functions required for the technical indicators\n",
    "start_time = time.time()\n",
    "tech_indicators = duckdb.sql('''\n",
    "                SELECT \"Open Time\",\n",
    "                        Close,\n",
    "                        Volume,\n",
    "                        AVG(\"Close\") OVER ( ORDER BY \"Open Time\"  \n",
    "                                            RANGE BETWEEN INTERVAL 14 SECONDS PRECEDING\n",
    "                                              AND INTERVAL 0 SECONDS FOLLOWING) as ma14,\n",
    "                        \n",
    "                        AVG(\"Close\") OVER ( ORDER BY \"Open Time\" \n",
    "                                            RANGE BETWEEN INTERVAL 28 SECONDS PRECEDING\n",
    "                                              AND INTERVAL 0 SECONDS FOLLOWING) as ma28,\n",
    "                                              \n",
    "                        STDDEV_POP(\"Close\") OVER ( ORDER BY \"Open Time\"  \n",
    "                                            RANGE BETWEEN INTERVAL 14 SECONDS PRECEDING\n",
    "                                              AND INTERVAL 0 SECONDS FOLLOWING) as stddev14,\n",
    "                        \n",
    "                        AVG(CASE WHEN Close - Open > 0 THEN Close - Open ELSE 0 END) OVER ( ORDER BY \"Open Time\"  \n",
    "                                            RANGE BETWEEN INTERVAL 14 SECONDS PRECEDING\n",
    "                                              AND INTERVAL 0 SECONDS FOLLOWING) AS avg_gain,\n",
    "                                              \n",
    "                        AVG(CASE WHEN Open - Close > 0 THEN Open - Close ELSE 0 END) OVER ( ORDER BY \"Open Time\"  \n",
    "                                            RANGE BETWEEN INTERVAL 14 SECONDS PRECEDING\n",
    "                                              AND INTERVAL 0 SECONDS FOLLOWING) AS avg_loss\n",
    "                FROM bc_full_dataset\n",
    "''')\n",
    "end_time = time.time()\n",
    "print(f'Total time taken: {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180b5b18-31dd-4df7-97d9-0524230dc10d",
   "metadata": {},
   "source": [
    "In the previous step, DuckDB has not yet processed the result. We will be using the columns from the previous step to calculate the bollinger bands and RSI in the next step and show the result. We see that DuckDB is able to compute the moving averages, bollinger bands and RSI on a 220 million row dataset in about 11min 28sec. Again note that all the data is processed on local machine with 16GB RAM and 4 cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1c1962ac-033e-4d16-aed7-5c5425f99162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────────────────┬─────────┬──────────┬───────────────────┬───┬───────────────────┬──────────┬──────────┬────────┐\n",
      "│      Open Time      │  Close  │  Volume  │       ma14        │ … │ middle_bollinger  │ avg_gain │ avg_loss │  rsi   │\n",
      "│      timestamp      │ double  │  double  │      double       │   │      double       │  double  │  double  │ double │\n",
      "├─────────────────────┼─────────┼──────────┼───────────────────┼───┼───────────────────┼──────────┼──────────┼────────┤\n",
      "│ 2017-08-17 04:00:28 │ 4261.48 │      0.1 │           4261.48 │ … │           4261.48 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 04:00:29 │ 4261.48 │      0.0 │           4261.48 │ … │           4261.48 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 04:00:30 │ 4261.48 │      0.0 │           4261.48 │ … │           4261.48 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 04:00:31 │ 4261.48 │      0.0 │           4261.48 │ … │           4261.48 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 04:00:32 │ 4261.48 │ 1.675183 │           4261.48 │ … │           4261.48 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 04:00:33 │ 4261.48 │      0.0 │           4261.48 │ … │           4261.48 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 04:00:34 │ 4261.48 │      0.0 │           4261.48 │ … │           4261.48 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 04:00:35 │ 4261.48 │      0.0 │           4261.48 │ … │           4261.48 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 04:00:36 │ 4261.48 │      0.0 │           4261.48 │ … │           4261.48 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 04:00:37 │ 4261.48 │      0.0 │ 4261.479999999999 │ … │ 4261.479999999999 │      0.0 │      0.0 │   NULL │\n",
      "│          ·          │    ·    │       ·  │         ·         │ · │         ·         │       ·  │       ·  │     ·  │\n",
      "│          ·          │    ·    │       ·  │         ·         │ · │         ·         │       ·  │       ·  │     ·  │\n",
      "│          ·          │    ·    │       ·  │         ·         │ · │         ·         │       ·  │       ·  │     ·  │\n",
      "│ 2017-08-17 06:46:58 │ 4345.45 │      0.0 │ 4345.449999999999 │ … │ 4345.449999999999 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 06:46:59 │ 4345.45 │      0.0 │ 4345.449999999999 │ … │ 4345.449999999999 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 06:47:00 │ 4345.45 │      0.0 │ 4345.449999999999 │ … │ 4345.449999999999 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 06:47:01 │ 4345.45 │      0.0 │ 4345.449999999999 │ … │ 4345.449999999999 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 06:47:02 │ 4345.45 │      0.0 │ 4345.449999999999 │ … │ 4345.449999999999 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 06:47:03 │ 4345.45 │      0.0 │ 4345.449999999999 │ … │ 4345.449999999999 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 06:47:04 │ 4345.45 │      0.0 │ 4345.449999999999 │ … │ 4345.449999999999 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 06:47:05 │ 4345.45 │      0.0 │ 4345.449999999999 │ … │ 4345.449999999999 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 06:47:06 │ 4345.45 │      0.0 │ 4345.449999999999 │ … │ 4345.449999999999 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 06:47:07 │ 4345.45 │      0.0 │ 4345.449999999999 │ … │ 4345.449999999999 │      0.0 │      0.0 │   NULL │\n",
      "├─────────────────────┴─────────┴──────────┴───────────────────┴───┴───────────────────┴──────────┴──────────┴────────┤\n",
      "│ ? rows (>9999 rows, 20 shown)                                                                  12 columns (8 shown) │\n",
      "└─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "Total time taken: 848.0323226451874\n",
      "CPU times: total: 38min 31s\n",
      "Wall time: 14min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Calculate the technical indicators and show the output\n",
    "start_time = time.time()\n",
    "duckdb.sql('''\n",
    "                SELECT \"Open Time\",\n",
    "                        Close,\n",
    "                        Volume,\n",
    "                        ma14,\n",
    "                        ma28,\n",
    "                        stddev14,\n",
    "                        ma14 + 2*stddev14 AS upper_bollinger,\n",
    "                        ma14 - 2*stddev14 AS lower_bollinger,\n",
    "                        ma14              AS middle_bollinger,\n",
    "                        avg_gain,\n",
    "                        avg_loss,\n",
    "                        100 - (100/(1+(avg_gain/avg_loss))) AS rsi\n",
    "                FROM tech_indicators\n",
    "''').show()\n",
    "end_time = time.time()\n",
    "print(f'Total time taken: {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03fffc9-c708-4cc3-b8d1-0f89733692ee",
   "metadata": {},
   "source": [
    "### Saving the technical indicators and writing to a parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d80dbc7a-bce5-40a7-bb53-f25c1cf5dbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken: 0.04151630401611328\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 41.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Calculate the 50 seconds moving average and 200 seconds moving average and show the output\n",
    "start_time = time.time()\n",
    "tech_indicators_out = duckdb.sql('''\n",
    "                SELECT \"Open Time\",\n",
    "                        Close,\n",
    "                        YEAR(\"Open Time\") as year,\n",
    "                        MONTH(\"Open Time\") as month,\n",
    "                        DAY(\"Open Time\") as day,\n",
    "                        Volume,\n",
    "                        ma14,\n",
    "                        ma28,\n",
    "                        stddev14,\n",
    "                        ma14 + 2*stddev14 AS upper_bollinger,\n",
    "                        ma14 - 2*stddev14 AS lower_bollinger,\n",
    "                        ma14              AS middle_bollinger,\n",
    "                        avg_gain,\n",
    "                        avg_loss,\n",
    "                        100 - (100/(1+(avg_gain/avg_loss))) AS rsi\n",
    "                FROM tech_indicators\n",
    "''')\n",
    "end_time = time.time()\n",
    "print(f'Total time taken: {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8799339-40b0-433d-8f93-f2301a8063df",
   "metadata": {},
   "source": [
    "In the step below, we write the technical indicators variable to a parquet file. We also use partitioning on year and month columns and partition it using hive partitioning format. Notice that we used zstd as the compression format. The whole process took about 20min and the output folder size is 10 GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebffeae8-7c27-46b7-a5f2-0c19787687c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1h 15min 47s\n",
      "Wall time: 20min 46s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x2d83e42f830>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# We are writing the technical indicators variable to a parquet file. We use zstd compression. \n",
    "# The file is also partitioned by year and month\n",
    "duckdb.execute('''COPY\n",
    "    (SELECT * FROM tech_indicators_out)\n",
    "    TO 'data/bc_full_dataset_tech_indicators.parquet'\n",
    "    (FORMAT 'parquet', CODEC 'zstd', PARTITION_BY (year, month));''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2c14e3-e859-455c-a6f3-ae471f23b5a1",
   "metadata": {},
   "source": [
    "### Comparing Parquet files with DuckDB native formats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3837879f-8b8d-4df2-8d30-a53df2ea9733",
   "metadata": {},
   "source": [
    "So far, we have tested DuckDB using the parquet file format. Next let us experiment with the DuckDB native format. For this we first create a DuckDB persistent stotrage connection below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6fd0ee22-c650-4cbd-bd1e-102afc13fbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 138 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "con = duckdb.connect('data/my_duck_db.duckdb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243fa8fa-bf13-4249-b511-640d9abe4e9e",
   "metadata": {},
   "source": [
    "We set the maximum amount of memory that DuckDB can use. This was set to 12.5GB by default. Because we are dealing with large datasets, we increase this limit to 20GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e293b135-f0b1-450f-97a4-aca9022beed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken: 0.0118560791015625\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 11.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = time.time()\n",
    "con.sql('''\n",
    "               SET memory_limit = '20GB';\n",
    "''')\n",
    "end_time = time.time()\n",
    "print(f'Total time taken: {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59f5665-c1ac-4a4c-9d28-cbea00b5dd1a",
   "metadata": {},
   "source": [
    "We create a DuckDB table in the next step from the partitioned parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e43ff875-2b68-4d38-9f2e-d4b6494efb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 58s\n",
      "Wall time: 8min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "con.sql('''CREATE TABLE bc_dataset_duckdb\n",
    "            AS\n",
    "            SELECT * \n",
    "            FROM read_parquet('data/bc_full_dataset_partitions/*/*/*.parquet',hive_partitioning=true)''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c69fcd-e7a3-4de7-bca5-00bc4340d2fa",
   "metadata": {},
   "source": [
    "In the next step, we run the same moving average 50 seconds and moving average 200 seconds calculation on the whole dataset but this time using the native DuckDB table. Notice that it took longer to compute the result compared to running the same analysis on Parquet files directly. This is an interesting observation. Another difference is that CPU usage time is less compared to parquet but overall time is more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "648ff8d6-b6f5-4048-aa0d-3df048b07f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────────────────┬─────────┬───────────────────┬───────────────────┐\n",
      "│      Open Time      │  Close  │       ma50        │       ma200       │\n",
      "│      timestamp      │ double  │      double       │      double       │\n",
      "├─────────────────────┼─────────┼───────────────────┼───────────────────┤\n",
      "│ 2017-08-17 04:00:28 │ 4261.48 │           4261.48 │           4261.48 │\n",
      "│ 2017-08-17 04:00:29 │ 4261.48 │           4261.48 │           4261.48 │\n",
      "│ 2017-08-17 04:00:30 │ 4261.48 │           4261.48 │           4261.48 │\n",
      "│ 2017-08-17 04:00:31 │ 4261.48 │           4261.48 │           4261.48 │\n",
      "│ 2017-08-17 04:00:32 │ 4261.48 │           4261.48 │           4261.48 │\n",
      "│ 2017-08-17 04:00:33 │ 4261.48 │           4261.48 │           4261.48 │\n",
      "│ 2017-08-17 04:00:34 │ 4261.48 │           4261.48 │           4261.48 │\n",
      "│ 2017-08-17 04:00:35 │ 4261.48 │           4261.48 │           4261.48 │\n",
      "│ 2017-08-17 04:00:36 │ 4261.48 │           4261.48 │           4261.48 │\n",
      "│ 2017-08-17 04:00:37 │ 4261.48 │ 4261.479999999999 │ 4261.479999999999 │\n",
      "│          ·          │    ·    │         ·         │         ·         │\n",
      "│          ·          │    ·    │         ·         │         ·         │\n",
      "│          ·          │    ·    │         ·         │         ·         │\n",
      "│ 2017-08-17 06:46:58 │ 4345.45 │ 4345.450000000001 │ 4345.449999999996 │\n",
      "│ 2017-08-17 06:46:59 │ 4345.45 │ 4345.450000000001 │ 4345.449999999996 │\n",
      "│ 2017-08-17 06:47:00 │ 4345.45 │ 4345.450000000002 │ 4345.449999999995 │\n",
      "│ 2017-08-17 06:47:01 │ 4345.45 │ 4345.450000000002 │ 4345.449999999995 │\n",
      "│ 2017-08-17 06:47:02 │ 4345.45 │ 4345.450000000002 │ 4345.449999999995 │\n",
      "│ 2017-08-17 06:47:03 │ 4345.45 │ 4345.450000000002 │ 4345.449999999995 │\n",
      "│ 2017-08-17 06:47:04 │ 4345.45 │ 4345.450000000003 │ 4345.449999999995 │\n",
      "│ 2017-08-17 06:47:05 │ 4345.45 │ 4345.450000000003 │ 4345.449999999994 │\n",
      "│ 2017-08-17 06:47:06 │ 4345.45 │ 4345.450000000003 │ 4345.449999999994 │\n",
      "│ 2017-08-17 06:47:07 │ 4345.45 │ 4345.449999999999 │ 4345.449999999998 │\n",
      "├─────────────────────┴─────────┴───────────────────┴───────────────────┤\n",
      "│ ? rows (>9999 rows, 20 shown)                               4 columns │\n",
      "└───────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "Total time taken: 289.87602972984314\n",
      "CPU times: total: 7min 32s\n",
      "Wall time: 4min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Calculate the 50 seconds moving average and 200 seconds moving average and show the output\n",
    "start_time = time.time()\n",
    "con.sql('''\n",
    "                SELECT \"Open Time\",\n",
    "                        Close,\n",
    "                        AVG(\"Close\") OVER ( ORDER BY \"Open Time\"  \n",
    "                                            RANGE BETWEEN INTERVAL 50 SECONDS PRECEDING\n",
    "                                              AND INTERVAL 0 SECONDS FOLLOWING) as ma50,\n",
    "                        AVG(\"Close\") OVER ( ORDER BY \"Open Time\" \n",
    "                                            RANGE BETWEEN INTERVAL 200 SECONDS PRECEDING\n",
    "                                              AND INTERVAL 0 SECONDS FOLLOWING) as ma200\n",
    "                FROM bc_dataset_duckdb\n",
    "''').show()\n",
    "end_time = time.time()\n",
    "print(f'Total time taken: {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ba1432-706a-477a-be5f-4db560f989e2",
   "metadata": {},
   "source": [
    "I tried adding indexes on the DuckDB table on \"Open Time\" and \"Close\" columns. I wanted to see if adding indexes made any difference. It took a few minutes to add both the indexes as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b4a095c8-19c5-4f4c-8cb3-a78af69450d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken: 363.7751486301422\n",
      "CPU times: total: 4min 6s\n",
      "Wall time: 6min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Add indexes on the `Open Time` column\n",
    "start_time = time.time()\n",
    "con.sql('''\n",
    "               CREATE INDEX open_time ON bc_dataset_duckdb(\"Open Time\");\n",
    "''')\n",
    "end_time = time.time()\n",
    "print(f'Total time taken: {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "76f2001e-ca62-4fa5-affe-af165b7856df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken: 141.13373160362244\n",
      "CPU times: total: 2min 53s\n",
      "Wall time: 2min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Add indexes on the `Close` column\n",
    "start_time = time.time()\n",
    "con.sql('''\n",
    "               CREATE INDEX close_value ON bc_dataset_duckdb(\"Close\");\n",
    "''')\n",
    "end_time = time.time()\n",
    "print(f'Total time taken: {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8facb7-aee2-485b-b494-d75c2deac110",
   "metadata": {},
   "source": [
    "After adding indexes, the overall time reduced from 4min 49 sec to 3min 6s. This is also faster compared to the time taken using the parquet files. But the CPU time remained the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "54eb6af2-ad3a-47e9-88c4-8cc8c562ed32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────────────────┬─────────┬───────────────────┬───────────────────┐\n",
      "│      Open Time      │  Close  │       ma50        │       ma200       │\n",
      "│      timestamp      │ double  │      double       │      double       │\n",
      "├─────────────────────┼─────────┼───────────────────┼───────────────────┤\n",
      "│ 2017-08-17 04:00:28 │ 4261.48 │           4261.48 │           4261.48 │\n",
      "│ 2017-08-17 04:00:29 │ 4261.48 │           4261.48 │           4261.48 │\n",
      "│ 2017-08-17 04:00:30 │ 4261.48 │           4261.48 │           4261.48 │\n",
      "│ 2017-08-17 04:00:31 │ 4261.48 │           4261.48 │           4261.48 │\n",
      "│ 2017-08-17 04:00:32 │ 4261.48 │           4261.48 │           4261.48 │\n",
      "│ 2017-08-17 04:00:33 │ 4261.48 │           4261.48 │           4261.48 │\n",
      "│ 2017-08-17 04:00:34 │ 4261.48 │           4261.48 │           4261.48 │\n",
      "│ 2017-08-17 04:00:35 │ 4261.48 │           4261.48 │           4261.48 │\n",
      "│ 2017-08-17 04:00:36 │ 4261.48 │           4261.48 │           4261.48 │\n",
      "│ 2017-08-17 04:00:37 │ 4261.48 │ 4261.479999999999 │ 4261.479999999999 │\n",
      "│          ·          │    ·    │         ·         │         ·         │\n",
      "│          ·          │    ·    │         ·         │         ·         │\n",
      "│          ·          │    ·    │         ·         │         ·         │\n",
      "│ 2017-08-17 06:46:58 │ 4345.45 │ 4345.450000000001 │ 4345.449999999996 │\n",
      "│ 2017-08-17 06:46:59 │ 4345.45 │ 4345.450000000001 │ 4345.449999999996 │\n",
      "│ 2017-08-17 06:47:00 │ 4345.45 │ 4345.450000000002 │ 4345.449999999995 │\n",
      "│ 2017-08-17 06:47:01 │ 4345.45 │ 4345.450000000002 │ 4345.449999999995 │\n",
      "│ 2017-08-17 06:47:02 │ 4345.45 │ 4345.450000000002 │ 4345.449999999995 │\n",
      "│ 2017-08-17 06:47:03 │ 4345.45 │ 4345.450000000002 │ 4345.449999999995 │\n",
      "│ 2017-08-17 06:47:04 │ 4345.45 │ 4345.450000000003 │ 4345.449999999995 │\n",
      "│ 2017-08-17 06:47:05 │ 4345.45 │ 4345.450000000003 │ 4345.449999999994 │\n",
      "│ 2017-08-17 06:47:06 │ 4345.45 │ 4345.450000000003 │ 4345.449999999994 │\n",
      "│ 2017-08-17 06:47:07 │ 4345.45 │ 4345.449999999999 │ 4345.449999999998 │\n",
      "├─────────────────────┴─────────┴───────────────────┴───────────────────┤\n",
      "│ ? rows (>9999 rows, 20 shown)                               4 columns │\n",
      "└───────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "Total time taken: 186.82496333122253\n",
      "CPU times: total: 7min 14s\n",
      "Wall time: 3min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Calculate the 50 seconds moving average and 200 seconds moving average and show the output\n",
    "start_time = time.time()\n",
    "con.sql('''\n",
    "                SELECT \"Open Time\",\n",
    "                        Close,\n",
    "                        AVG(\"Close\") OVER ( ORDER BY \"Open Time\"  \n",
    "                                            RANGE BETWEEN INTERVAL 50 SECONDS PRECEDING\n",
    "                                              AND INTERVAL 0 SECONDS FOLLOWING) as ma50,\n",
    "                        AVG(\"Close\") OVER ( ORDER BY \"Open Time\" \n",
    "                                            RANGE BETWEEN INTERVAL 200 SECONDS PRECEDING\n",
    "                                              AND INTERVAL 0 SECONDS FOLLOWING) as ma200\n",
    "                FROM bc_dataset_duckdb\n",
    "''').show()\n",
    "end_time = time.time()\n",
    "print(f'Total time taken: {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4c8389-156d-45e0-803d-4dc0f395f68b",
   "metadata": {},
   "source": [
    "In the last step, I tried calculating the other technical indicators as well. These include moving average 14 seconds and 28 seconds, Bollinger bands and RSI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "62e14c2c-40b3-4b79-b3b0-e4af077bb74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken: 0.0\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Calculate the window functions required for the technical indicators\n",
    "start_time = time.time()\n",
    "tech_indicators_duckdb = con.sql('''\n",
    "                SELECT \"Open Time\",\n",
    "                        Close,\n",
    "                        Volume,\n",
    "                        AVG(\"Close\") OVER ( ORDER BY \"Open Time\"  \n",
    "                                            RANGE BETWEEN INTERVAL 14 SECONDS PRECEDING\n",
    "                                              AND INTERVAL 0 SECONDS FOLLOWING) as ma14,\n",
    "                        \n",
    "                        AVG(\"Close\") OVER ( ORDER BY \"Open Time\" \n",
    "                                            RANGE BETWEEN INTERVAL 28 SECONDS PRECEDING\n",
    "                                              AND INTERVAL 0 SECONDS FOLLOWING) as ma28,\n",
    "                                              \n",
    "                        STDDEV_POP(\"Close\") OVER ( ORDER BY \"Open Time\"  \n",
    "                                            RANGE BETWEEN INTERVAL 14 SECONDS PRECEDING\n",
    "                                              AND INTERVAL 0 SECONDS FOLLOWING) as stddev14,\n",
    "                        \n",
    "                        AVG(CASE WHEN Close - Open > 0 THEN Close - Open ELSE 0 END) OVER ( ORDER BY \"Open Time\"  \n",
    "                                            RANGE BETWEEN INTERVAL 14 SECONDS PRECEDING\n",
    "                                              AND INTERVAL 0 SECONDS FOLLOWING) AS avg_gain,\n",
    "                                              \n",
    "                        AVG(CASE WHEN Open - Close > 0 THEN Open - Close ELSE 0 END) OVER ( ORDER BY \"Open Time\"  \n",
    "                                            RANGE BETWEEN INTERVAL 14 SECONDS PRECEDING\n",
    "                                              AND INTERVAL 0 SECONDS FOLLOWING) AS avg_loss\n",
    "                FROM bc_dataset_duckdb\n",
    "''')\n",
    "end_time = time.time()\n",
    "print(f'Total time taken: {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6731bf51-ffaf-4def-a19c-26e06654d53b",
   "metadata": {},
   "source": [
    "Below we see that even after adding indexes, the DuckDB table took longer time to compute the results compared to the Parquet files. Again notice that while the overall time is more than time taken for computation onparquet files, the CPU time is lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "86f68a2e-3359-4e21-a5d9-6371e8bd7905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────────────────┬─────────┬──────────┬───────────────────┬───┬───────────────────┬──────────┬──────────┬────────┐\n",
      "│      Open Time      │  Close  │  Volume  │       ma14        │ … │ middle_bollinger  │ avg_gain │ avg_loss │  rsi   │\n",
      "│      timestamp      │ double  │  double  │      double       │   │      double       │  double  │  double  │ double │\n",
      "├─────────────────────┼─────────┼──────────┼───────────────────┼───┼───────────────────┼──────────┼──────────┼────────┤\n",
      "│ 2017-08-17 04:00:28 │ 4261.48 │      0.1 │           4261.48 │ … │           4261.48 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 04:00:29 │ 4261.48 │      0.0 │           4261.48 │ … │           4261.48 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 04:00:30 │ 4261.48 │      0.0 │           4261.48 │ … │           4261.48 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 04:00:31 │ 4261.48 │      0.0 │           4261.48 │ … │           4261.48 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 04:00:32 │ 4261.48 │ 1.675183 │           4261.48 │ … │           4261.48 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 04:00:33 │ 4261.48 │      0.0 │           4261.48 │ … │           4261.48 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 04:00:34 │ 4261.48 │      0.0 │           4261.48 │ … │           4261.48 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 04:00:35 │ 4261.48 │      0.0 │           4261.48 │ … │           4261.48 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 04:00:36 │ 4261.48 │      0.0 │           4261.48 │ … │           4261.48 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 04:00:37 │ 4261.48 │      0.0 │ 4261.479999999999 │ … │ 4261.479999999999 │      0.0 │      0.0 │   NULL │\n",
      "│          ·          │    ·    │       ·  │         ·         │ · │         ·         │       ·  │       ·  │     ·  │\n",
      "│          ·          │    ·    │       ·  │         ·         │ · │         ·         │       ·  │       ·  │     ·  │\n",
      "│          ·          │    ·    │       ·  │         ·         │ · │         ·         │       ·  │       ·  │     ·  │\n",
      "│ 2017-08-17 06:46:58 │ 4345.45 │      0.0 │ 4345.449999999999 │ … │ 4345.449999999999 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 06:46:59 │ 4345.45 │      0.0 │ 4345.449999999999 │ … │ 4345.449999999999 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 06:47:00 │ 4345.45 │      0.0 │ 4345.449999999999 │ … │ 4345.449999999999 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 06:47:01 │ 4345.45 │      0.0 │ 4345.449999999999 │ … │ 4345.449999999999 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 06:47:02 │ 4345.45 │      0.0 │ 4345.449999999999 │ … │ 4345.449999999999 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 06:47:03 │ 4345.45 │      0.0 │ 4345.449999999999 │ … │ 4345.449999999999 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 06:47:04 │ 4345.45 │      0.0 │ 4345.449999999999 │ … │ 4345.449999999999 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 06:47:05 │ 4345.45 │      0.0 │ 4345.449999999999 │ … │ 4345.449999999999 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 06:47:06 │ 4345.45 │      0.0 │ 4345.449999999999 │ … │ 4345.449999999999 │      0.0 │      0.0 │   NULL │\n",
      "│ 2017-08-17 06:47:07 │ 4345.45 │      0.0 │ 4345.449999999999 │ … │ 4345.449999999999 │      0.0 │      0.0 │   NULL │\n",
      "├─────────────────────┴─────────┴──────────┴───────────────────┴───┴───────────────────┴──────────┴──────────┴────────┤\n",
      "│ ? rows (>9999 rows, 20 shown)                                                                  12 columns (8 shown) │\n",
      "└─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "Total time taken: 1027.3476815223694\n",
      "CPU times: total: 33min 15s\n",
      "Wall time: 17min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Calculate the technical indicators and show the output\n",
    "start_time = time.time()\n",
    "con.sql('''\n",
    "                SELECT \"Open Time\",\n",
    "                        Close,\n",
    "                        Volume,\n",
    "                        ma14,\n",
    "                        ma28,\n",
    "                        stddev14,\n",
    "                        ma14 + 2*stddev14 AS upper_bollinger,\n",
    "                        ma14 - 2*stddev14 AS lower_bollinger,\n",
    "                        ma14              AS middle_bollinger,\n",
    "                        avg_gain,\n",
    "                        avg_loss,\n",
    "                        100 - (100/(1+(avg_gain/avg_loss))) AS rsi\n",
    "                FROM tech_indicators_duckdb\n",
    "''').show()\n",
    "end_time = time.time()\n",
    "print(f'Total time taken: {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "debc85e5-8351-46ef-a9dd-1f0199e72845",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad704fe-4c69-4a85-87fb-2fa4cf668310",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
